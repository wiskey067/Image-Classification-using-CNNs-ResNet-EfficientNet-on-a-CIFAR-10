
ğŸ“Œ Project: Image Classification using CNN, ResNet-50, and EfficientNet-B0 on CIFAR-10

This project explores image classification on the CIFAR-10 dataset using three different deep learning architectures:
	â€¢	Simple CNN (baseline)
	â€¢	ResNet-50 (deep residual network with skip connections)
	â€¢	EfficientNet-B0 (optimized scaling-based model)

ğŸš€ Objective

To compare the performance of traditional CNNs with modern architectures (ResNet and EfficientNet) and analyze trade-offs in accuracy, complexity, and training time.

ğŸ“‚ Dataset
	â€¢	CIFAR-10: 60,000 images (32Ã—32 RGB) across 10 classes
	â€¢	Training: 50,000 images | Test: 10,000 images

ğŸ› ï¸ Implementation
	â€¢	Framework: TensorFlow/Keras
	â€¢	Loss Function: Categorical Crossentropy
	â€¢	Optimizer: Adam/SGD
	â€¢	Batch Size: 1560 (custom setting)
	â€¢	Epochs: CNN (25), ResNet-50 (20â€“25), EfficientNet-B0 (30â€“40)
	â€¢	Used early stopping to prevent overfitting

ğŸ“Š Results

Model	Test Accuracy
CNN	70.52%
ResNet-50	71.77%
EfficientNet-B0	72.57%

Observation:
	â€¢	EfficientNet-B0 slightly outperformed ResNet-50 and CNN.
	â€¢	Trend: CNN < ResNet-50 < EfficientNet-B0
	â€¢	Results show the impact of architecture depth and scaling efficiency.

âœ… Key Takeaways
	â€¢	Even without pretrained weights, deep architectures achieve decent accuracy on CIFAR-10.
	â€¢	EfficientNet converges faster with fewer parameters compared to ResNet-50.
	â€¢	Simple CNN provides a quick baseline but struggles with complex features.

ğŸ“Œ Future Improvements
	â€¢	Use data augmentation (random crop, flip, rotation, cutout).
	â€¢	Experiment with pretrained weights (ImageNet) for transfer learning.
	â€¢	Fine-tune with learning rate schedulers (cosine annealing, OneCycle).
	â€¢	Try CIFAR-100 for more challenging classification.

